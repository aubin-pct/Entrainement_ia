# üìå 5√®me rendu : Perceptron

## üìù Description du Rendu

Le projet consiste en l'impl√©mentation et l'entra√Ænement d'un perceptron pour la classification binaire. Il est structur√© de mani√®re √† permettre une visualisation des donn√©es ainsi que de la fronti√®re de d√©cision qui s√©pare les deux classes. Le perceptron utilise une fonction d'activation de type seuil (step function) pour effectuer les pr√©dictions.

### Objectifs du Projet :

- **G√©n√©ration des Donn√©es** : Importation du dataset Iris, suivi d'une r√©duction de dimensionnalit√© via l'Analyse en Composantes Principales (PCA) pour ne conserver que les deux premi√®res dimensions principales. Ce processus permet de visualiser et classifier les donn√©es dans un espace 2D tout en conservant un maximum d'information.
- **Impl√©mentation du Perceptron** : Cr√©ation d'une classe `Perceptron` permettant d'initialiser les param√®tres d'entra√Ænement (taux d'apprentissage, nombre d'it√©rations, poids, biais), d'effectuer la fonction d'activation, d'entra√Æner le mod√®le et de faire des pr√©dictions.
- **Visualisation** : Affichage des points sur un graphique, avec un code couleur pour les classes "Label 0" et "Label 1", ainsi que la fronti√®re de d√©cision obtenue par le perceptron.
- **Tests Comparatifs** : Comparaison des performances entre diff√©rents mod√®les :

  - Un perceptron simple.
  - Deux perceptrons en s√©rie.
  - Deux perceptrons en parall√®le.

## üìÇ Structure du Rendu

Le projet est organis√© comme suit :

* `Perceptron.py` : Contient la classe `Perceptron`, avec ses m√©thodes pour l'entra√Ænement et la pr√©diction des donn√©es.
* `app.py` : Ex√©cute l'entra√Ænement et affiche les r√©sultats avec les graphes de pr√©cision et la fronti√®re de d√©cision.

## üìö M√©mo sur le Perceptron

### Qu'est-ce qu'un Perceptron ?

Le perceptron est un mod√®le de r√©seau de neurones artificiels utilis√© pour les t√¢ches de classification binaire. Il est compos√© de plusieurs entr√©es, de poids associ√©s √† chaque entr√©e, d'un biais, et d'une fonction d'activation. Le perceptron est un classificateur lin√©aire, ce qui signifie qu'il s√©pare les donn√©es en deux classes via une fronti√®re lin√©aire.

### Fonctionnement du Perceptron

1. **Entr√©es et Poids** :Soit un vecteur d'entr√©es X = (x_1, x_2, ..., x_n) et des poids W = (w_1, w_2, ..., w_n), associ√©s √† un biais b.
2. **Calcul de la Sortie** :La sortie z est une combinaison lin√©aire des entr√©es et des poids :
   - z = X . W + b
3. **Fonction d'Activation (Seuil)** :La sortie z passe par une fonction d'activation (step function) qui retourne :
   - y = 1 si z >= 0, 0 sinon
4. **Entra√Ænement** :Les poids sont ajust√©s √† chaque it√©ration selon la r√®gle de mise √† jour :
   - W <- W + aplha * (y_true - y_pred) . X
   - b <- b + aplha * (y_true - y_pred)
     O√π alpha est le taux d'apprentissage.
5. **Pr√©diction** :
   Une fois entra√Æn√©, le perceptron pr√©dit la classe d'un nouvel exemple en utilisant la fonction d'activation avec les poids et le biais appris.

### Calculs Associ√©s

- **Sortie du perceptron** :
  - z = X . W + b
- **Mise √† jour des poids** :
  - W <- W + aplha * (y_true - y_pred) . X
- **Fonction d'activation** :
  - y = 1 si z >= 0, 0 sinon

## √âtude du Dataset Iris

Il contient des informations sur **150 iris** r√©partis en trois classes :  **Iris-setosa** ,  **Iris-versicolor** , et  **Iris-virginica** , avec 50 √©chantillons par classe. Chaque √©chantillon est d√©crit par **quatre caract√©ristiques** :

1. La longueur du s√©pale
2. La largeur du s√©pale
3. La longueur du p√©tale
4. La largeur du p√©tale

Ces caract√©ristiques sont des variables quantitatives continues et mesur√©es en centim√®tres.

Pour cet exercice, nous avons r√©duit le probl√®me √† un cas binaire o√π la classe Iris-setosa (Label 0) est s√©par√©e des autres classes (Label 1). L'objectif est de classer les iris en deux cat√©gories, et nous avons utilis√© la r√©duction de dimensionnalit√© avec PCA pour simplifier les donn√©es tout en conservant 95 % de la variance d'origine.

#### Conclusion

L'utilisation de la r√©duction de dimensionnalit√© avec PCA a grandement facilit√© la t√¢che de classification. Le  Perceptron, m√™me avec sa simplicit√©, a r√©ussi √†  s√©parer efficacement les classes . La visualisation des fronti√®res de d√©cision montre que les donn√©es sont bien s√©par√©es dans l'espace transform√© par PCA, ce qui illustre l'efficacit√© de cette approche pour des probl√®mes de classification simples.

## üöÄ Lancement

```
	python app.py
```

    ou

```
	python3 app.py

```

## **üì∏ Sorties**

#### üìà Graphiques

##### 1/ Perceptron simple

![perceptron](img/perceptron.png)

##### 2/ Evolution de l'accuracy

![accuracy](img/accuracy.png)

##### 3/ Deux perceptron en serie

![perceptron_serie](img/perceptron_serie.png)

##### 4/ Deux perceptron en parall√®le

![para](img/perceptron_parallele.png)

## ‚ú® Auteurs

Ce projet a √©t√© r√©alis√© dans le cadre de l'analyse et la mod√©lisation de donn√©es avec une approche de classification ordinale et r√©duction de dimension.
