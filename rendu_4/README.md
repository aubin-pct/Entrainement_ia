# üìå 4√®me rendu : Ordinal Classification avec PCA et Analyse de Corr√©lation

## üìù Description du Rendu

Ce projet impl√©mente une classification ordinale en combinant plusieurs techniques d'analyse de donn√©es, notamment :

* L'analyse de corr√©lation entre les variables
* La r√©gression lin√©aire pour les variables fortement corr√©l√©es
* La transformation d'une variable cible en une variable cat√©gorielle
* L'application de l'Analyse en Composantes Principales (PCA)
* L'√©valuation des performances du mod√®le et comparaison avec d'autres mod√©les avec des courbes ROC

## üìÇ Structure du Rendu

Le projet est organis√© comme suit :

* `OrdinalClassification.py` : Classe impl√©mentant la r√©gression logistique ordinale.
* `LogistiqueRegression.py` : Impl√©mentation de la r√©gression logistique standard.
* `Scaler.py` : Classe impl√©mentant la normalisation min et max.
* `PolynomialRegression.py` : Classe impl√©mentant la r√©gression polynomiale, calcule le MSE & R¬≤ et normalise avec Scaler.py.

## üöÄ Lancement

```
	python app.py
```

    ou

```
	python3 app.py

```

## üß† Utilisation de la PCA

L'Analyse en Composantes Principales (PCA) a √©t√© utilis√©e pour r√©duire la dimensionnalit√© du jeu de donn√©es, afin de :

* **Simplifier le mod√®le** tout en conservant l'information essentielle.
* **Am√©liorer les performances** en √©liminant les variables redondantes ou peu informatives, ce qui permet de r√©duire le bruit et pr√©venir le sur-apprentissage.
* **Rendre les variables moins corr√©l√©es** en transformant les donn√©es de mani√®re √† ce que les nouvelles composantes principales soient ind√©pendantes entre elles.Faciliter l'interpr√©tation et la visualisation des donn√©es en projetant celles-ci dans un espace de dimension r√©duite.

## üìä R√©sultats

* **Matrice de corr√©lation** : Identification des variables fortement corr√©l√©es pour mieux orienter la r√©gression.
* **R√©gressions lin√©aires** : Analyse des relations entre variables corr√©l√©es.
* **Test de Spearman** : Corr√©lations significatives entre les variables, par exemple :
  * **MEDV x LSTAT** : Corr√©lation n√©gative forte (-0.85), indiquant que le prix des maisons diminue avec un statut socio-√©conomique plus bas.
  * **MEDV x RM** : Corr√©lation positive forte (0.63), sugg√©rant que plus de pi√®ces par logement est associ√© √† un prix plus √©lev√©.
* **Test de Chi2** : Mise en √©vidence de relations entre la variable cible et des variables qualitatives :
  * **MEDV_category x RAD** : Relation forte avec le nombre de routes accessibles (p < 0.05).
  * **MEDV_category x CHAS** : Relation plus faible avec la proximit√© de la rivi√®re Charles (p ‚âà 0.05).
* **Test d'ANOVA** : Impact des variables continues sur `MEDV_category` :
  * **RM** : Plus de pi√®ces par logement est associ√© √† un prix plus √©lev√© (p ‚â™ 0.05).
  * **LSTAT** : Un statut socio-√©conomique plus bas correspond √† des prix plus faibles (p ‚â™ 0.05).
* **Analyse comparative des mod√®les** : La r√©gression logistique ordinale avec PCA atteint une pr√©cision moyenne de  57 % , avec une meilleure pr√©diction des classes  0 et 2 , tandis que la classe 1 reste plus difficile √† classifier. En revanche, Random Forest et XGBoost affichent une pr√©cision  parfaitement optimis√©e (100%) , ce qui peut indiquer un sur-apprentissage. SVM offre un bon compromis avec une pr√©cision de  83 % , montrant une capacit√© de g√©n√©ralisation sup√©rieure √† la r√©gression logistique tout en √©vitant l'overfitting observ√© avec les mod√®les d'ensemble.

### **üì∏ Sorties**

#### üìà Graphiques

##### 1/ Matrice de corr√©lation

![matrice de corr√©lation](img/matrice_correlation.png)

##### 2/ R√©gression des variables fortement corr√©l√©es

![graphes de regression](img/regression_graphe.png)

##### 3/ R√©gressions lin√©aires entre les entr√©es et la sortie (transform√©e en variable cat√©gorielle)

![graphes r√©gressions de la variable cible](img/regression_target_graphe.png)

##### 4/ R√©gression Logistique x PCA

![courbe ROC Logistique regression](img/courbe_ROC_Logistique_PCA.png)

##### 5/ Courbes ROC Comparaison

![graphe ROC](https://file+.vscode-resource.vscode-cdn.net/home/ob1/Documents/Entrainement_ia/rendu_4/img/ROC_graphe.png)

#### üíª Terminal

Regression logistique - Cross Validation - Accuracy : 0.5688
Rapport de Classification :
               precision    recall  f1-score   support

    0       0.51      0.85      0.64       169
           1       0.63      0.34      0.44       171
           2       0.66      0.52      0.58       166

    accuracy                           0.57       506
   macro avg       0.60      0.57      0.55       506
weighted avg       0.60      0.57      0.55       506

Random Forest - Cross Validation - Accuracy : 0.7846
Rapport de Classification :
               precision    recall  f1-score   support

    0       0.88      0.80      0.84       169
           1       0.67      0.77      0.72       171
           2       0.83      0.78      0.80       166

    accuracy                           0.78       506
   macro avg       0.80      0.78      0.79       506
weighted avg       0.79      0.78      0.79       506

XGBoost - Cross Validation - Accuracy : 0.7747
Rapport de Classification :
               precision    recall  f1-score   support

    0       0.83      0.81      0.82       169
           1       0.69      0.71      0.70       171
           2       0.82      0.81      0.81       166

    accuracy                           0.77       506
   macro avg       0.78      0.78      0.78       506
weighted avg       0.78      0.77      0.78       506

SVM - Cross Validation - Accuracy : 0.5119
Rapport de Classification :
               precision    recall  f1-score   support

    0       0.68      0.63      0.65       169
           1       0.33      0.19      0.24       171
           2       0.48      0.73      0.58       166

    accuracy                           0.51       506
   macro avg       0.50      0.51      0.49       506
weighted avg       0.50      0.51      0.49       506

## ‚ú® Auteurs

Ce projet a √©t√© r√©alis√© dans le cadre de l'analyse et la mod√©lisation de donn√©es avec une approche de classification ordinale et r√©duction de dimension.
