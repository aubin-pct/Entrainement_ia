# üìå 8√®me rendu : Classification D'images - CNN

## üìù Description du Rendu

Ce projet consiste en la mise en place d'un mod√®le de classification d'images bas√© sur un r√©seau de neurones convolutifs (CNN). L'objectif principal est d'entra√Æner un mod√®le sur le dataset MNIST afin de reconna√Ætre des chiffres manuscrits. Le projet inclut √©galement une exp√©rimentation sur des images modifi√©es en augmentant leur taille et en les repositionnant de mani√®re al√©atoire avant de les r√©duire √† la taille originale.

## üèÜ Objectifs du projet

* Construire un mod√®le CNN performant pour la classification des chiffres manuscrits du dataset MNIST.
* Visualiser l'√©volution des m√©triques d'apprentissage (accuracy et loss).
* G√©n√©rer et tester des images alt√©r√©es pour observer la robustesse du mod√®le.
* Analyser les performances √† l'aide de m√©triques telles que la matrice de confusion et le rapport de classification.

## üìä R√©sultats

* **Performance du mod√®le** : Le mod√®le a √©t√© entra√Æn√© sur 10 √©poques et a atteint un niveau de pr√©cision significatif sur l'ensemble de test.
* **Visualisation des m√©triques** : Des graphiques d'√©volution de l'accuracy et de la perte ont √©t√© g√©n√©r√©s pour mieux comprendre l'apprentissage du mod√®le.
* **Exp√©rimentation sur images alt√©r√©es** : Un ensemble d'images a √©t√© modifi√© pour tester la robustesse du mod√®le, et les r√©sultats ont √©t√© analys√©s √† l'aide d'une matrice de confusion.

## üìÇ Structure du Rendu

‚îú‚îÄ‚îÄ model/                  		 # Dossier contenant le mod√®le entra√Æn√©
‚îÇ   ‚îú‚îÄ‚îÄ mon_model.keras      # Mod√®le sauvegard√©
‚îú‚îÄ‚îÄimg/
‚îÇ   ‚îú‚îÄ‚îÄ accuracy_loss.png
‚îÇ   ‚îú‚îÄ‚îÄ matrice_conf_1.png   # Matrice de confusion - donn√©es MNIST
‚îÇ   ‚îú‚îÄ‚îÄ matrice_conf_2.png   # Matrice de confusion - donn√©es cr√©√©es
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ rendu_8_CNN_RNN.ipynb       # Script contenant le code du mod√®le CNN x RNN
‚îú‚îÄ‚îÄ rendu_8_CNN.ipynb                 # Script contenant le code du mod√®le CNN simple

## Dataset MNIST

Le dataset MNIST est un ensemble de donn√©es bien connu pour la classification d'images de chiffres manuscrits. Il contient :

* 60 000 images pour l'entra√Ænement
* 10 000 images pour le test
  Chaque image est en niveaux de gris et de taille 28x28 pixels.

## Existant

Atteindre une pr√©cision sup√©rieure √† 99% sur les tests MNIST n'est pas tr√®s compliqu√©. Cependant, il devient plus difficile pour le mod√®le de reconna√Ætre les chiffres lorsque ceux-ci sont modifi√©s (rotation, d√©calage, zoom) via  *ImageDataGenerator* , et encore plus lorsqu'on utilise la fonction *create_imperfect_image* que j'ai √©crite, qui r√©duit et affine les chiffres.

L'objectif ici est d'optimiser les performances du mod√®le face √† ces deux types de modifications avant d'augmenter la taille du jeu de donn√©es.

Pour choisir la bonne architecture, le mod√®le a √©t√© entra√Æn√© avec les 60 000 images du jeu de donn√©es d'entra√Ænement de base, compl√©t√©es par 20 000 images g√©n√©r√©es par *ImageDataGenerator* et 25 000 images g√©n√©r√©es par  *create_imperfect_image* . Bien s√ªr, le jeu de donn√©es sera √©quilibr√© lors de l'entra√Ænement final, l'objectif √©tant d'obtenir un mod√®le capable de bien g√©n√©raliser.

### Architecture du mod√®le

Pour l'architecture de la couche de convolution, je me suis inspir√© de cet article qui montre qu'apr√®s tests, une architecture avec deux couches de convolution suivies d'un pooling est plus efficace qu'une autre approche. (Source : [Brendan Artley - MNIST Keras Simple CNN](https://medium.com/@BrendanArtley/mnist-keras-simple-cnn-99-6-731b624aee7f))

En ce qui concerne l'utilisation des r√©seaux de neurones r√©currents (RNN), comme le montre cet article ([RNN for MNIST Classification - Kaggle](https://www.kaggle.com/code/mikolajbabula/rnn-for-mnist-classification-tensor-flow)), un RNN simple ne surpasse pas un CNN. Toutefois, la question se pose : qu'en est-il de la combinaison des deux ? Faut-il privil√©gier un r√©seau enti√®rement connect√© ou un r√©seau r√©current ?

Apr√®s avoir test√© plusieurs architectures et optimis√© les hyperparam√®tres gr√¢ce aux algorithmes de recherche al√©atoire et bay√©sienne, et valid√© les mod√®les via la validation crois√©e, voici les r√©sultats :

### R√©sultats

* **Mod√®le CNN** : Ce mod√®le atteint une pr√©cision de 98 % sur le jeu de test, qui comprend 10 000 images de base, 10 000 images g√©n√©r√©es par *create_imperfect_image* et 10 000 images g√©n√©r√©es par  *ImageDataGenerator* . Il est √† la fois rapide, performant et g√©n√®re des r√©sultats similaires sur les ensembles d'entra√Ænement et de validation, ce qui montre une bonne g√©n√©ralisation et une pr√©cision satisfaisante. (Voir Annexe 1 pour plus de d√©tails sur la structure)
* **Mod√®le CNN x RNN (GRU)** : Ce mod√®le obtient une pr√©cision similaire √† celle du mod√®le CNN, mais il est consid√©rablement plus lent. (Voir Annexe 2 pour plus de d√©tails sur la structure)

## üöÄ Lancemement

Ce rendu a √©t√© r√©alis√© sur un notebook, o√π tous les r√©sultats sont d√©j√† affich√©s dans le fichier `rendu_8.ipynb`.

## **üì∏ Sorties**

Vous trouverez les sorties dans les notebook *rendu_8_CNN_RNN.ipynb* et *rendu_8_CNN_RNN.ipynb*

## Annexe

### 1/ Code CNN classique

```
model = tf.keras.models.Sequential([
      Conv2D(32, (3, 3), activation='relu', padding="same", input_shape=(28, 28, 1)),
      BatchNormalization(),
      Conv2D(32, (3, 3), activation='relu', padding="same", input_shape=(28, 28, 1)),
      BatchNormalization(),
      MaxPooling2D((2,2), strides=2),
      Dropout(0.3),

      Conv2D(64, (3, 3), activation='relu', padding="same"),
      BatchNormalization(),
      Conv2D(64, (3, 3), activation='relu', padding="same"),
      BatchNormalization(),
      MaxPooling2D((2,2), strides=2),
      Dropout(0.3),

      Conv2D(128, (3, 3), activation='relu', padding="same"),
      BatchNormalization(),
      Conv2D(128, (3, 3), activation='relu', padding="same"),
      BatchNormalization(),
      MaxPooling2D((2,2), strides=2),
      Dropout(0.3),

      Flatten(),

      Dense(512, activation='relu'),
      Dropout(0.25),
      BatchNormalization(),
      Dense(512, activation='relu'),
      Dropout(0.5),
      BatchNormalization(),

      Dense(10, activation="softmax")
  ])
  optimizer = AdamW(learning_rate=0.0001)
  model.compile(optimizer=optimizer, loss="sparse_categorical_crossentropy", metrics=['accuracy'])
```

### 2/ Code CNN x RNN (GRU)

```
model = tf.keras.models.Sequential([
      Conv2D(32, (3, 3), activation='relu', padding="same", input_shape=(28, 28, 1)),
      BatchNormalization(),
      Conv2D(32, (3, 3), activation='relu', padding="same", input_shape=(28, 28, 1)),
      BatchNormalization(),
      MaxPooling2D((2,2), strides=2),
      Dropout(0.3),

      Conv2D(64, (3, 3), activation='relu', padding="same"),
      BatchNormalization(),
      Conv2D(64, (3, 3), activation='relu', padding="same"),
      BatchNormalization(),
      MaxPooling2D((2,2), strides=2),
      Dropout(0.3),

      Conv2D(128, (3, 3), activation='relu', padding="same"),
      BatchNormalization(),
      Conv2D(128, (3, 3), activation='relu', padding="same"),
      BatchNormalization(),
      MaxPooling2D((2,2), strides=2),
      Dropout(0.3),

      Reshape((-1, 128)),

      Bidirectional(GRU(512, activation='relu', return_sequences=True)),
      Dropout(0.25),

      Bidirectional(GRU(256, activation='relu')),
      Dropout(0.5),

      Dense(10, activation="softmax")
  ])
  optimizer = Adam(learning_rate=0.001, weight_decay=0.0001)
  model.compile(optimizer=optimizer, loss="sparse_categorical_crossentropy", metrics=['accuracy'])
```
